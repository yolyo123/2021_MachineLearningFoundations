{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"15.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN58b0ogUe4dpvVzhlbxHgv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Qj8Ey0j_2Kiq","executionInfo":{"status":"ok","timestamp":1636448142987,"user_tz":-480,"elapsed":5,"user":{"displayName":"陳佑甄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzIUBUXR24tLoip4QQgjhsStGIG9hzjbafxUsz=s64","userId":"10990682828848697792"}}},"source":["import numpy as np\n","import math"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFiEwK1e2jhN","executionInfo":{"status":"ok","timestamp":1636449103500,"user_tz":-480,"elapsed":223587,"user":{"displayName":"陳佑甄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzIUBUXR24tLoip4QQgjhsStGIG9hzjbafxUsz=s64","userId":"10990682828848697792"}},"outputId":"3fab11aa-71ad-4b69-b0a8-097435d4a7fd"},"source":["def generateD(X, Y, size, iter):\n","  np.random.seed(iter)\n","  for i in range(size):\n","    #隨機取0或1，將0視為-1\n","    y = np.random.randint(0, 2) \n","\n","    if y == 1:\n","      Y.append([y])\n","      mean = [2, 3]\n","      cov = [[0.6, 0], [0, 0.6]]  # diagonal covariance\n","    else:\n","      Y.append([y-1])\n","      mean = [0, 4]\n","      cov = [[0.4, 0], [0, 0.4]]  # diagonal covariance\n","\n","    xi = np.random.multivariate_normal(mean, cov, 1)\n","    Xi = np.array([1])\n","    Xi = np.append(Xi, xi)\n","    X.append(Xi)\n","\n","if __name__ == '__main__':\n","  iteration = 100\n","  train_size = 200\n","  test_size = 5000\n","  Eout_lin = []\n","  Eout_log = []\n","\n","  for iter in range(iteration):\n","    # Generate Data\n","    trainX = []\n","    trainY = []\n","    testX = []\n","    testY = []\n","    generateD(trainX, trainY, train_size, iter)\n","    generateD(testX, testY, test_size, iter)\n","    trainX = np.asarray(trainX)\n","    trainY = np.asarray(trainY)\n","    testX = np.asarray(testX)\n","    testY = np.asarray(testY)\n","\n","  # Linear Reg\n","    # Calculate pseudo-inverse\n","    trainX_cross = np.linalg.pinv(trainX)\n","    # Calculate WLIN = X_cross ‧ Y\n","    WLIN = np.matmul(trainX_cross, trainY)\n","    # print(WLIN)\n","    # Calculate Eout\n","    EoutN = 0\n","    for i in range(test_size):\n","      h_xn = np.matmul(WLIN.T, testX[i])\n","      if np.sign(h_xn) != testY[i]:\n","        EoutN += 1\n","    # print(\"EoutN: \", EoutN)\n","    Eout = EoutN/test_size\n","    # print(\"Eout: \", Eout)\n","    Eout_lin.append(Eout)\n","\n","  # Logistic Reg\n","    T = 500\n","    eta = 0.1\n","    W = np.zeros(3)\n","    for i in range(T):\n","      GDN = 0\n","      # Gradient Descent : 1/N[1+...+N(theta(-yn WT Xn)(-yn Xn))]\n","      for j in range(train_size):\n","        # theta(-yn WT Xn) = exp(-yn WT Xn)/(1 + exp(-yn WT Xn))\n","        s = -trainY[j] * np.matmul(W.T, trainX[j])\n","        theta = np.exp(s)/(1 + np.exp(s))\n","        GDN += theta * -trainY[j] * trainX[j]\n","      # print(\"GDN: \", GDN)\n","      GD = GDN / train_size\n","      # print(\"GD: \", GD)\n","      # update : Wt+1 = Wt - eta*GD\n","      W = W - (eta * GD)\n","    # print(\"W: \", W)\n","    \n","    # Calculate Eout\n","    EoutN = 0\n","    l = []\n","    for i in range(test_size):\n","      h_xn = np.matmul(W.T, testX[i])\n","      if np.sign(h_xn) != testY[i]:\n","        EoutN += 1\n","    # print(\"EoutN: \", EoutN)\n","    Eout = EoutN/test_size\n","    # print(\"Eout: \", Eout)\n","    Eout_log.append(Eout)\n","\n","  # print(\"Eout_lin: \",Eout_lin)\n","  # print(\"Eout_log: \",Eout_log)\n","  Eout_lin_avg = np.mean(Eout_lin)\n","  Eout_log_avg = np.mean(Eout_log)\n","  print(\"Eout_lin_avg: \",Eout_lin_avg)\n","  print(\"Eout_log_avg: \",Eout_log_avg)\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Eout_lin_avg:  0.057684000000000006\n","Eout_log_avg:  0.05918599999999999\n"]}]}]}