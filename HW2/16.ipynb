{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"16.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOja0pbYAb7byI1G2Of3rRV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Qj8Ey0j_2Kiq","executionInfo":{"status":"ok","timestamp":1636467633075,"user_tz":-480,"elapsed":3,"user":{"displayName":"陳佑甄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzIUBUXR24tLoip4QQgjhsStGIG9hzjbafxUsz=s64","userId":"10990682828848697792"}}},"source":["import numpy as np\n","import math"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFiEwK1e2jhN","executionInfo":{"status":"ok","timestamp":1636467852211,"user_tz":-480,"elapsed":215967,"user":{"displayName":"陳佑甄","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzIUBUXR24tLoip4QQgjhsStGIG9hzjbafxUsz=s64","userId":"10990682828848697792"}},"outputId":"ac3afcd0-9c53-443e-9951-55c217fffbf1"},"source":["def generateD(X, Y, size, iter):\n","  np.random.seed(iter)\n","  for i in range(size):\n","    #隨機取0或1，將0視為-1\n","    y = np.random.randint(0, 2) \n","\n","    if y == 1:\n","      Y.append([y])\n","      mean = [2, 3]\n","      cov = [[0.6, 0], [0, 0.6]]  # diagonal covariance\n","    else:\n","      Y.append([y-1])\n","      mean = [0, 4]\n","      cov = [[0.4, 0], [0, 0.4]]  \n","\n","    xi = np.random.multivariate_normal(mean, cov, 1)\n","    Xi = np.array([1])\n","    Xi = np.append(Xi, xi)\n","    X.append(Xi)\n","def generateO(X, Y, size, iter):\n","  np.random.seed(iter)\n","  for i in range(size):\n","\n","    Y.append([1])\n","    mean = [6, 0]\n","    cov = [[0.3, 0], [0, 0.1]]\n","\n","    xi = np.random.multivariate_normal(mean, cov, 1)\n","    Xi = np.array([1])\n","    Xi = np.append(Xi, xi)\n","    X.append(Xi)\n","\n","if __name__ == '__main__':\n","  iteration = 100\n","  train_size = 200\n","  test_size = 5000\n","  out_size = 20\n","  Eout_lin = []\n","  Eout_log = []\n","\n","  for iter in range(iteration):\n","    # Generate Data\n","    trainX = []\n","    trainY = []\n","    testX = []\n","    testY = []\n","    generateD(trainX, trainY, train_size, iter)\n","    generateO(trainX, trainY, out_size, iter)\n","    generateD(testX, testY, test_size, iter)\n","    trainX = np.asarray(trainX)\n","    trainY = np.asarray(trainY)\n","    testX = np.asarray(testX)\n","    testY = np.asarray(testY)\n","\n","  # Linear Reg\n","    # Calculate pseudo-inverse\n","    trainX_cross = np.linalg.pinv(trainX)\n","    # Calculate WLIN = X_cross ‧ Y\n","    WLIN = np.matmul(trainX_cross, trainY)\n","    # print(WLIN)\n","    # Calculate Eout\n","    EoutN = 0\n","    for i in range(test_size):\n","      h_xn = np.matmul(WLIN.T, testX[i])\n","      if np.sign(h_xn) != testY[i]:\n","        EoutN += 1\n","    # print(\"EoutN: \", EoutN)\n","    Eout = EoutN/test_size\n","    # print(\"Eout: \", Eout)\n","    Eout_lin.append(Eout)\n","\n","  # Logistic Reg\n","    T = 500\n","    eta = 0.1\n","    W = np.zeros(3)\n","    for i in range(T):\n","      GDN = 0\n","      # Gradient Descent : 1/N[1+...+N(theta(-yn WT Xn)(-yn Xn))]\n","      for j in range(train_size + out_size):\n","        # theta(-yn WT Xn) = exp(-yn WT Xn)/(1 + exp(-yn WT Xn))\n","        s = -trainY[j] * np.matmul(W.T, trainX[j])\n","        theta = np.exp(s)/(1 + np.exp(s))\n","        GDN += theta * -trainY[j] * trainX[j]\n","      GD = GDN / (train_size + out_size)\n","\n","      # update : Wt+1 = Wt - eta*GD\n","      W = W - (eta * GD)\n","    # print(\"W: \", W)\n","    \n","    # Calculate Eout\n","    EoutN = 0\n","    l = []\n","    for i in range(test_size):\n","      h_xn = np.matmul(W.T, testX[i])\n","      if np.sign(h_xn) != testY[i]:\n","        EoutN += 1\n","    # print(\"EoutN: \", EoutN)\n","    Eout = EoutN/test_size\n","    # print(\"Eout: \", Eout)\n","    Eout_log.append(Eout)\n","\n","  print(\"Eout_lin: \",Eout_lin)\n","  print(\"Eout_log: \",Eout_log)\n","  Eout_lin_avg = np.mean(Eout_lin)\n","  Eout_log_avg = np.mean(Eout_log)\n","  print(\"Eout_lin_avg: \",Eout_lin_avg)\n","  print(\"Eout_log_avg: \",Eout_log_avg)\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Eout_lin:  [0.0788, 0.1054, 0.1108, 0.118, 0.0904, 0.1292, 0.0766, 0.116, 0.0932, 0.0864, 0.0832, 0.1088, 0.0538, 0.0604, 0.089, 0.1236, 0.0648, 0.0724, 0.0712, 0.0914, 0.0826, 0.0674, 0.0888, 0.1062, 0.089, 0.0718, 0.1008, 0.093, 0.0882, 0.0848, 0.0858, 0.088, 0.073, 0.113, 0.0864, 0.1024, 0.0796, 0.1138, 0.096, 0.0886, 0.0682, 0.1042, 0.075, 0.0918, 0.0802, 0.0944, 0.078, 0.0738, 0.0842, 0.0982, 0.0918, 0.0918, 0.0772, 0.0804, 0.111, 0.094, 0.1054, 0.0938, 0.0616, 0.094, 0.1196, 0.0688, 0.1034, 0.0936, 0.1138, 0.0742, 0.1036, 0.1088, 0.0886, 0.1088, 0.0878, 0.0992, 0.0854, 0.0922, 0.0898, 0.0836, 0.1252, 0.0686, 0.1056, 0.0752, 0.0934, 0.1022, 0.0798, 0.106, 0.1106, 0.103, 0.119, 0.07, 0.1052, 0.0942, 0.085, 0.0874, 0.105, 0.0826, 0.0908, 0.1184, 0.0914, 0.1096, 0.0728, 0.1018]\n","Eout_log:  [0.0614, 0.0572, 0.0604, 0.0628, 0.0544, 0.0628, 0.063, 0.0544, 0.0684, 0.0572, 0.0628, 0.0582, 0.0488, 0.0582, 0.053, 0.0644, 0.0556, 0.0554, 0.0642, 0.0642, 0.0574, 0.0558, 0.0618, 0.0552, 0.0562, 0.0546, 0.0608, 0.0584, 0.0622, 0.067, 0.0582, 0.0602, 0.0586, 0.057, 0.0572, 0.0622, 0.0584, 0.064, 0.0576, 0.0606, 0.0634, 0.0628, 0.0642, 0.0598, 0.0608, 0.0598, 0.0564, 0.05, 0.0556, 0.0554, 0.0616, 0.0572, 0.0592, 0.0578, 0.059, 0.057, 0.0572, 0.0628, 0.0608, 0.0592, 0.056, 0.0562, 0.0612, 0.0552, 0.062, 0.0568, 0.0602, 0.0598, 0.059, 0.0628, 0.0636, 0.0612, 0.0596, 0.0528, 0.0586, 0.0586, 0.0624, 0.0594, 0.0582, 0.0554, 0.057, 0.0558, 0.0598, 0.0626, 0.0656, 0.0578, 0.0604, 0.0594, 0.062, 0.0618, 0.0596, 0.0586, 0.062, 0.0506, 0.0554, 0.0586, 0.0634, 0.0546, 0.0642, 0.0576]\n","Eout_lin_avg:  0.09195600000000002\n","Eout_log_avg:  0.05915999999999998\n"]}]}]}